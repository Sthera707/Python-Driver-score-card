{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f53cceb",
   "metadata": {},
   "source": [
    "The objective of the project is to build a drivers score card that can aid a business to measure the drivers performance based on depot departure, Customer TAT and Depot return. The aim is to create a weighted average per driver and give them intensive based on the grading system. ghhhhh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce04eb9",
   "metadata": {},
   "source": [
    "Importing all the libraries and Data that will be neccessary for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236e32ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ae1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "file_path = r'C:\\Users\\SthembisoM\\Desktop\\Karl\\Driver score card\\Trackmatic details.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af58c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de94b73",
   "metadata": {},
   "source": [
    "Data Exploration: Check missing values and duplicates on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf1995",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows = df[df.duplicated()]\n",
    "if not duplicate_rows.empty:\n",
    "    print(\"Duplicate rows found:\")\n",
    "    print(duplicate_rows)\n",
    "else:\n",
    "    print(\"No duplicate rows found in the dataset.\")\n",
    "\n",
    "missing_values = df.isna().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb4fd49",
   "metadata": {},
   "source": [
    "Drop missing data because the trackmatic detail dataset doesnt have any shipment numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d9f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Shipment'])\n",
    "df = df.dropna(subset=['Driver', 'Customer'])\n",
    "missing_values = df.isna().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92ed3a1",
   "metadata": {},
   "source": [
    "Correct datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d171de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of columns with timestamps to convert\n",
    "timestamp_columns = ['Requested Delivery Date', 'Planned Route Start', 'Planned Route End', 'Actual Route Start', 'Actual Route End', 'Actual Arrival', 'Planned Departure', 'Actual Departure', 'Planned MST', 'Actual TAT', 'Planned Arrival', 'Actual Route Duration']\n",
    "\n",
    "# Loop through each timestamp column and convert its data type\n",
    "for column in timestamp_columns:\n",
    "    df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "\n",
    "# Optional: Check the data types of the columns after conversion\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad24b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ed0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_route_statuses = df['Route Status'].unique()\n",
    "\n",
    "# Print the unique strings\n",
    "for status in unique_route_statuses:\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544ec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Route Status'].isin(['Active', 'Requested'])]\n",
    "unique_route_statuses = df['Route Status'].unique()\n",
    "\n",
    "# Print the unique strings\n",
    "for status in unique_route_statuses:\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b700e45",
   "metadata": {},
   "source": [
    "Drop All Pull Forward or rolled over routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04bfd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = df['Actual Route Start'].dt.date != df['Actual Route End'].dt.date\n",
    "\n",
    "# Use the condition to exclude rows where Planned and Actual Start Dates are different\n",
    "df = df[~condition]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600b04d",
   "metadata": {},
   "source": [
    "Drop All sleepouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a0867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = df['Planned Route Start'].dt.date != df['Planned Route End'].dt.date\n",
    "\n",
    "df = df[~condition]\n",
    "\n",
    "condition = (df['Planned Route Start'].dt.date == df['Planned Route End'].dt.date)\n",
    "\n",
    "# Use the condition to exclude rows where Planned Start Date and Planned End Date are different\n",
    "df = df[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95816f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c49b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Planned Route Start'].dt.date == df['Actual Route Start'].dt.date]\n",
    "df['Departure Time Variance'] = df['Actual Route Start'] - df['Planned Route Start']\n",
    "\n",
    "df['Departure Time Variance (minutes)'] = df['Departure Time Variance'].dt.total_seconds() / 60\n",
    "print(df['Departure Time Variance (minutes)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63abe21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de9ca1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'Adj Actual Wait TAT',\n",
    "    'Adj Actual Off-Load TAT',\n",
    "    'Adj Actual Doc TAT',\n",
    "    'Off-Loading TAT per Case (sec)',\n",
    "    'CSD Planned after 6pm',\n",
    "    'CSD Arrived after 6pm',\n",
    "    'PSD Planned after 4pm',\n",
    "    'PSD Arrived after 4pm',\n",
    "    'Mall Split',\n",
    "    'Outlier',\n",
    "    'Exception']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85ac9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "condition = (df['Actual Route Duration'].dt.hour * 60 + df['Actual Route Duration'].dt.minute) >= 60\n",
    "\n",
    "# Use the condition to exclude rows with a Trip Duration less than 1 hour in the original DataFrame\n",
    "df = df[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564a0382",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = ~((df['Planned Route Start'].dt.hour >= 7) | (df['Planned Route Start'].dt.hour < 1))\n",
    "\n",
    "# Use the condition to exclude rows with Actual Start Time between 07:00 and 01:00\n",
    "df = df[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d8f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = ~((df['Actual Route Start'].dt.hour >= 10) | (df['Actual Route Start'].dt.hour < 1))\n",
    "\n",
    "#Use the condition to exclude rows with Actual Start Time between 13:00 and 01:00\n",
    "df = df[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eadf0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8455c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the row with the maximum 'Departure Time Variance (minutes)'\n",
    "max_idx = df['Departure Time Variance (minutes)'].idxmax()\n",
    "\n",
    "# Find the index of the row with the minimum 'Departure Time Variance (minutes)'\n",
    "min_idx = df['Departure Time Variance (minutes)'].idxmin()\n",
    "\n",
    "# Access the rows with the maximum and minimum values\n",
    "max_row = df.loc[max_idx]\n",
    "min_row = df.loc[min_idx]\n",
    "\n",
    "# Print the rows\n",
    "print(\"Row with Maximum Variance:\")\n",
    "print(max_row)\n",
    "\n",
    "print(\"\\nRow with Minimum Variance:\")\n",
    "print(min_row)\n",
    "\n",
    "\n",
    "max_variance = df['Departure Time Variance (minutes)'].max()\n",
    "min_variance = df['Departure Time Variance (minutes)'].min()\n",
    "\n",
    "print(f\"Maximum Variance: {max_variance} minutes\")\n",
    "print(f\"Minimum Variance: {min_variance} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5d0282",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_stats = df['Departure Time Variance (minutes)'].describe()\n",
    "print(variance_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = df['Departure Time Variance (minutes)']\n",
    "\n",
    "# Create a histogram with specified number of bins (you can adjust this)\n",
    "plt.hist(dt, bins=20, edgecolor='k')\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('Departure Time Variance (minutes)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Departure Time Variance')\n",
    "\n",
    "# Show the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b6a7ff",
   "metadata": {},
   "source": [
    "Based on these statistics:\n",
    "\n",
    "The mean departure time variance being positive (8.38 minutes) suggests that, on average, departures tend to be slightly later than planned.\n",
    "\n",
    "The standard deviation being relatively large (47.49 minutes) indicates a wide spread of departure time variances, with some instances of significant delays and early departures.\n",
    "\n",
    "The presence of negative values (e.g., minimum of -255.63 minutes) indicates instances where departures occurred earlier than planned.\n",
    "\n",
    "The maximum departure time variance of 478.35 minutes suggests that there are cases of substantial delays in departures.\n",
    "\n",
    "In conclucsion I am satisfied with the data quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccdc780",
   "metadata": {},
   "source": [
    "Creating Category for dispatching pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d00e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Planned Route Start' and 'Actual Route Start' columns to datetime format\n",
    "df['Planned Route Start'] = pd.to_datetime(df['Planned Route Start'])\n",
    "df['Actual Route Start'] = pd.to_datetime(df['Actual Route Start'])\n",
    "\n",
    "# Filter the DataFrame based on date comparison\n",
    "df = df[df['Planned Route Start'].dt.date == df['Actual Route Start'].dt.date]\n",
    "\n",
    "# Continue with the calculations and categorizations\n",
    "\n",
    "# Filter the DataFrame based on date comparison\n",
    "#df = df[df['Planned Route Start'].dt.date == df['Actual Route Start'].dt.date]\n",
    "\n",
    "# Calculate 'Departure Time Variance' and 'Departure Time Variance (minutes)'\n",
    "df['Departure Time Variance'] = df['Actual Route Start'] - df['Planned Route Start']\n",
    "df['Departure Time Variance (minutes)'] = df['Departure Time Variance'].dt.total_seconds() / 60\n",
    "\n",
    "# Define the categorization function\n",
    "def categorize_departure_variance(minutes):\n",
    "    if minutes <= -120:\n",
    "        return 'Dispatched 2hrs+ Earlier'\n",
    "    elif minutes > -120 and minutes <= -60:\n",
    "        return 'Dispatched 1-2 hrs early'\n",
    "    elif minutes > -60 and minutes <= -30:\n",
    "        return 'Dispatched 30min-1hr early'\n",
    "    elif minutes > -30 and minutes <= 30:\n",
    "        return 'On Time'\n",
    "    elif minutes > 30 and minutes <= 60:\n",
    "        return 'Dispatched 30min-1hr late'\n",
    "    elif minutes > 60 and minutes < 120:\n",
    "        return 'Dispatched 1hr-2hrs late'\n",
    "    else:\n",
    "        return 'Dispatched 2hrs+ late'\n",
    "\n",
    "# Apply the custom function to create a new column\n",
    "df['Dispatch Variance Category'] = df['Departure Time Variance (minutes)'].apply(categorize_departure_variance)\n",
    "\n",
    "# Display the DataFrame with the new category column\n",
    "print(df[['Departure Time Variance (minutes)', 'Dispatch Variance Category']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab419b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe390d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Planned Route End' and 'Actual Route End' columns to datetime format\n",
    "df['Planned Route End'] = pd.to_datetime(df['Planned Route End'])\n",
    "df['Actual Route End'] = pd.to_datetime(df['Actual Route End'])\n",
    "\n",
    "# Filter the DataFrame based on date comparison\n",
    "df = df[df['Planned Route End'].dt.date == df['Actual Route End'].dt.date]\n",
    "\n",
    "# Calculate 'Depot Return Variance' and 'Depot Return Variance (minutes)'\n",
    "df['Depot Return Variance'] = df['Actual Route End'] - df['Planned Route End']\n",
    "df['Depot Return Variance (minutes)'] = df['Depot Return Variance'].dt.total_seconds() / 60\n",
    "\n",
    "# Define the categorization function\n",
    "def categorize_departure_variance(minutes):\n",
    "    if minutes <= -120:\n",
    "        return 'Returned 2hrs+ Earlier'\n",
    "    elif minutes > -120 and minutes <= -60:\n",
    "        return 'Returned 1-2 hrs early'\n",
    "    elif minutes > -60 and minutes <= -30:\n",
    "        return 'Returned 30min-1hr early'\n",
    "    elif minutes > -30 and minutes <= 30:\n",
    "        return 'On Time'\n",
    "    elif minutes > 30 and minutes <= 60:\n",
    "        return 'Returned 30min-1hr late'\n",
    "    elif minutes > 60 and minutes < 120:\n",
    "        return 'Returned 1hr-2hrs late'\n",
    "    else:\n",
    "        return 'Returned 2hrs+ late'\n",
    "\n",
    "# Apply the custom function to create a new column\n",
    "df['Depot Return Variance Category'] = df['Depot Return Variance (minutes)'].apply(categorize_departure_variance)\n",
    "\n",
    "# Display the DataFrame with the new category column\n",
    "print(df[['Depot Return Variance (minutes)', 'Depot Return Variance Category']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7d58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Actual Route End' and 'Actual Route Start' columns to datetime format\n",
    "df['Actual Route End'] = pd.to_datetime(df['Actual Route End'])\n",
    "df['Actual Route Start'] = pd.to_datetime(df['Actual Route Start'])\n",
    "\n",
    "# Convert 'Actual TAT' and 'Planned MST' columns to datetime\n",
    "df['Actual TAT'] = pd.to_datetime(df['Actual TAT'], errors='coerce')\n",
    "df['Planned MST'] = pd.to_datetime(df['Planned MST'], errors='coerce')\n",
    "\n",
    "# Filter the DataFrame to include only rows where 'Actual Route End' and 'Actual Route Start' have the same date\n",
    "df = df[df['Actual Route End'].dt.date == df['Actual Route Start'].dt.date]\n",
    "\n",
    "# Calculate 'TAT Variance' and 'TAT Variance (Minutes)'\n",
    "df['TAT Variance'] = df['Actual TAT'] - df['Planned MST']\n",
    "df['TAT Variance (Minutes)'] = df['TAT Variance'].dt.total_seconds() / 60\n",
    "\n",
    "# Filter the DataFrame to keep only rows with TAT Variance greater than or equal to 20 minutes\n",
    "df = df[df['TAT Variance (Minutes)'] >= 20]\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "def categorize_TA_variance(minutes):\n",
    "    if minutes > 0 and minutes <= 30:\n",
    "        return '0 <TAT <=30'\n",
    "    elif minutes > 30 and minutes <= 60:\n",
    "        return '30 <TAT <=60'\n",
    "    elif minutes > 60 and minutes <= 120:\n",
    "        return '60 <TAT <=120'\n",
    "    elif minutes > 120 and minutes <= 180:\n",
    "        return '120 <TAT <=180'\n",
    "    elif minutes > 180 and minutes <= 240:\n",
    "        return '180 <TAT <=240'\n",
    "    else:\n",
    "        return 'TAT 4hrs +'\n",
    "\n",
    "# Apply the custom function to create a new column\n",
    "df['TAT Variance Category'] = df['TAT Variance (Minutes)'].apply(categorize_TA_variance)\n",
    "\n",
    "print(df[['TAT Variance Category', 'TAT Variance (Minutes)']])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91423a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_stats = df['TAT Variance (Minutes)'].describe()\n",
    "print(variance_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd72289",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f3d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = df[['TAT Variance (Minutes)']]\n",
    "\n",
    "# Create a histogram with specified number of bins (you can adjust this)\n",
    "plt.hist(dt, bins=20, edgecolor='k')\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel(['TAT Variance (Minutes)'])\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of TAT Variance')\n",
    "\n",
    "# Show the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f318aa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59096c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Driver_Score_Dispatch'] = df['Dispatch Variance Category'].apply(\n",
    "    lambda x: 3 if x == 'Dispatched 2hrs+ Earlier' else\n",
    "    (5 if x == 'Dispatched 1-2 hrs early' else\n",
    "    (10 if x == 'Dispatched 30min-1hr early' else\n",
    "     (10 if x == 'On Time' else\n",
    "      (5 if x == 'Dispatched 30min-1hr late' else\n",
    "       (3 if x == 'Dispatched 1hr-2hrs late' else 1))\n",
    "    )\n",
    "    )\n",
    "))\n",
    "\n",
    "driver_Dispatch_performance = df.groupby('Driver').agg(\n",
    "    Number_of_Routes=pd.NamedAgg(column='Dispatch Variance Category', aggfunc='count'),\n",
    "    Driver_Score_Dispatch=pd.NamedAgg(column='Driver_Score_Dispatch', aggfunc='sum')\n",
    ")\n",
    "\n",
    "# Calculate the driver score as a percentage\n",
    "driver_Dispatch_performance['Driver_Score_Percentage'] = (driver_Dispatch_performance['Driver_Score_Dispatch'] /\n",
    "                                                  (driver_Dispatch_performance['Number_of_Routes']*10))*100\n",
    "\n",
    "# Sort the results by the number of routes in descending order\n",
    "driver_Dispatch_performance = driver_Dispatch_performance.sort_values(by='Number_of_Routes', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(driver_Dispatch_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29912c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a639825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Driver_Score_Return'] = df['Depot Return Variance Category'].apply(\n",
    "    lambda x: 10 if x == 'Returned 2hrs+ Earlier' else\n",
    "    (10 if x == 'Returned 1-2 hrs early' else\n",
    "    (10 if x == 'Returned 30min-1hr early' else\n",
    "     (10 if x == 'On Time' else\n",
    "      (3 if x == 'Returned 30min-1hr late' else\n",
    "       (1 if x == 'Returned 1hr-2hrs late' else 0))\n",
    "    )\n",
    "    )\n",
    "))\n",
    "\n",
    "driver_Return_performance = df.groupby('Driver').agg(\n",
    "    Number_of_Routes=pd.NamedAgg(column='Depot Return Variance Category', aggfunc='count'),\n",
    "    Driver_Score_Return=pd.NamedAgg(column='Driver_Score_Return', aggfunc='sum')\n",
    ")\n",
    "\n",
    "# Calculate the driver score as a percentage\n",
    "driver_Return_performance['Driver_Return_Score_Percentage'] = (driver_Dispatch_performance['Driver_Score_Dispatch'] /\n",
    "                                                  (driver_Dispatch_performance['Number_of_Routes']*10))*100\n",
    "\n",
    "# Sort the results by the number of routes in descending order\n",
    "driver_Return_performance = driver_Return_performance.sort_values(by='Number_of_Routes', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(driver_Return_performance)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c1d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Driver_TAT_Score'] = df['TAT Variance Category'].apply(\n",
    "    lambda x: 10 if x == '0 <TAT <=30' else\n",
    "    (8 if x == '30 <TAT <=60' else\n",
    "    (5 if x == '60 <TAT <=120' else\n",
    "     (3 if x == '120 <TAT <=180' else\n",
    "      (1 if x == '180 <TAT <=240' else 0)\n",
    "    )\n",
    "    )\n",
    "))\n",
    "\n",
    "driver_TAT_performance = df.groupby('Driver').agg(\n",
    "    Number_of_Routes=pd.NamedAgg(column='TAT Variance Category', aggfunc='count'),\n",
    "    Driver_Score_TAT=pd.NamedAgg(column='Driver_TAT_Score', aggfunc='sum')\n",
    ")\n",
    "\n",
    "# Calculate the driver score as a percentage\n",
    "driver_TAT_performance['Driver_TAT_Score_Percentage'] = (driver_TAT_performance['Driver_Score_TAT'] /\n",
    "                                                  (driver_TAT_performance['Number_of_Routes']*10))*100\n",
    "\n",
    "# Sort the results by the number of routes in descending order\n",
    "driver_TAT_performance = driver_TAT_performance.sort_values(by='Number_of_Routes', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(driver_TAT_performance, driver_Return_performance, driver_Dispatch_performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7818c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the weighted score for each driver in each performance category\n",
    "driver_TAT_performance['Weighted_Score_TAT'] = (driver_TAT_performance['Driver_TAT_Score_Percentage'] * 0.4)\n",
    "driver_Return_performance['Weighted_Score_Return'] = (driver_Return_performance['Driver_Return_Score_Percentage'] * 0.3)\n",
    "driver_Dispatch_performance['Weighted_Score_Dispatch'] = (driver_Dispatch_performance['Driver_Score_Percentage'] * 0.3)\n",
    "\n",
    "# Combine the three DataFrames into one, using the 'Driver' column as the index\n",
    "driver_combined_performance = pd.concat([driver_TAT_performance, driver_Return_performance, driver_Dispatch_performance], axis=1)\n",
    "\n",
    "# Calculate the total weighted score by summing the scores from each category\n",
    "driver_combined_performance['Total_Weighted_Score'] = (\n",
    "    driver_combined_performance['Weighted_Score_TAT'] +\n",
    "    driver_combined_performance['Weighted_Score_Return'] +\n",
    "    driver_combined_performance['Weighted_Score_Dispatch']\n",
    ")\n",
    "\n",
    "# Select the relevant columns for the final DataFrame\n",
    "weighted_score_df = driver_combined_performance[['Number_of_Routes', 'Total_Weighted_Score']]\n",
    "\n",
    "# Sort drivers by their total weighted scores in descending order\n",
    "weighted_score_df = weighted_score_df.sort_values(by='Total_Weighted_Score', ascending=False)\n",
    "\n",
    "# Reset the index to have a clean index without duplicate driver names\n",
    "weighted_score_df.reset_index(inplace=True)\n",
    "\n",
    "# Display the results\n",
    "print(weighted_score_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb9203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
